# SnowCore Permian Command Center

**Intelligent Yield & Graph-Based RCA Command Center** for the merged SnowCore/TeraField Permian Basin gathering network.

## Overview

Following the acquisition of TeraField Resources, this demo showcases how Snowflake's AI capabilities can unify disconnected gathering networks and predict systemic risks across the combined infrastructure.

### Key Features

- **ðŸ—ºï¸ Unified Network Visualization**: Interactive geospatial map showing SnowCore (Blue) and TeraField (Red) assets with pipeline connections
- **ðŸ¤– AutoGL Link Prediction**: Graph neural network that discovers hidden dependencies between the two networks
- **ðŸ’¬ AI Integration Assistant**: Cortex Agent that bridges live SCADA data with legacy engineering specs
- **âš ï¸ Pressure Risk Detection**: Real-time alerts when routing decisions would exceed equipment limits

### The "Wow" Moment

Click "Run AutoGL Prediction" and watch the system:
1. Draw new edges connecting previously disconnected clusters
2. Flag **TF-V-204** as high risk
3. Explain: *"Increased flow from SnowCore Pad 42 will exceed the 600 PSI pressure rating of this legacy TeraField valve (detected via PDF extraction)"*

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUTOGL_YIELD_OPTIMIZATION                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ASSET_MASTER â”‚  â”‚SCADA_       â”‚  â”‚NETWORK_     â”‚  â”‚GRAPH_      â”‚ â”‚
â”‚  â”‚             â”‚  â”‚TELEMETRY    â”‚  â”‚EDGES        â”‚  â”‚PREDICTIONS â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                â”‚                â”‚                â”‚        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                     Snowflake Notebook                          â”‚â”‚
â”‚  â”‚   â€¢ PyTorch Geometric (via Network Rule)                        â”‚â”‚
â”‚  â”‚   â€¢ GraphSAGE for link prediction                               â”‚â”‚
â”‚  â”‚   â€¢ Anomaly scoring                                             â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                     Cortex AI Services                          â”‚â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚â”‚
â”‚  â”‚   â”‚Cortex       â”‚  â”‚Cortex       â”‚  â”‚Cortex       â”‚            â”‚â”‚
â”‚  â”‚   â”‚Analyst      â”‚  â”‚Search       â”‚  â”‚Agent        â”‚            â”‚â”‚
â”‚  â”‚   â”‚(SQL/NL)     â”‚  â”‚(RAG/Docs)   â”‚  â”‚(Reasoning)  â”‚            â”‚â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                 â”‚                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                    Streamlit App                                 â”‚â”‚
â”‚  â”‚   â€¢ Network Map (Plotly Scattergeo)                             â”‚â”‚
â”‚  â”‚   â€¢ Simulation Controls                                          â”‚â”‚
â”‚  â”‚   â€¢ AI Chat Interface                                            â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Prerequisites

- Snowflake account with ACCOUNTADMIN access
- Snowflake CLI (`snow`) installed and configured
- Python 3.11+ (for data generation only)

## Quick Start

### 1. Clone and Generate Data

```bash
cd autogl_yield_optimization

# Generate synthetic demo data (deterministic, seed=42)
python3 utils/generate_synthetic_data.py
```

### 2. Deploy to Snowflake

```bash
# Deploy all resources (uses default "demo" connection)
./deploy.sh

# Or specify a different Snowflake CLI connection
./deploy.sh -c myconnection

# Deploy to a specific environment (DEV, PROD)
./deploy.sh --prefix DEV
./deploy.sh --prefix PROD -c prod_connection

# Redeploy individual components (faster iteration)
./deploy.sh --only-streamlit      # Redeploy Streamlit app only
./deploy.sh --only-notebook       # Redeploy notebook only
./deploy.sh --only-data           # Reload data only
./deploy.sh --only-sql            # Run SQL setup only
```

This creates:
- Database: `AUTOGL_YIELD_OPTIMIZATION`
- Schema: `AUTOGL_YIELD_OPTIMIZATION`
- Role: `AUTOGL_YIELD_OPTIMIZATION_ROLE`
- Warehouse: `AUTOGL_YIELD_OPTIMIZATION_WH`
- Compute Pool: `AUTOGL_YIELD_OPTIMIZATION_COMPUTE_POOL`
- Tables: `ASSET_MASTER`, `NETWORK_EDGES`, `SCADA_TELEMETRY`, `GRAPH_PREDICTIONS`, `SCADA_AGGREGATES`
- Cortex Search: `AUTOGL_YIELD_OPTIMIZATION_DOCS_SEARCH`
- Semantic View: `AUTOGL_YIELD_OPTIMIZATION_ANALYTICS_VIEW`
- Streamlit App: `AUTOGL_YIELD_OPTIMIZATION_APP`
- Notebook: `AUTOGL_YIELD_OPTIMIZATION_NOTEBOOK`

### 3. Run the AutoGL Notebook

**Option A: Command Line (Headless)**
```bash
./run.sh main                    # Execute notebook
./run.sh status                  # Check resource status
./run.sh streamlit               # Get Streamlit app URL
./run.sh --prefix DEV status     # Check DEV environment
```

**Option B: Interactive (Snowsight)**
1. Open Snowsight â†’ Notebooks
2. Open `AUTOGL_YIELD_OPTIMIZATION_NOTEBOOK`
3. The `AUTOGL_YIELD_OPTIMIZATION_EXTERNAL_ACCESS` integration is already attached
4. Run all cells to generate predictions

### 4. Launch the Dashboard

1. Open Snowsight â†’ Streamlit
2. Launch `AUTOGL_YIELD_OPTIMIZATION_APP`
3. Explore the Network Map and Simulation Chat

## Directory Structure

```
autogl_yield_optimization/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ synthetic/           # Pre-generated CSVs (version controlled)
â”‚   â”‚   â”œâ”€â”€ asset_master.csv
â”‚   â”‚   â”œâ”€â”€ network_edges.csv
â”‚   â”‚   â”œâ”€â”€ scada_telemetry.csv
â”‚   â”‚   â””â”€â”€ graph_predictions.csv
â”‚   â””â”€â”€ documents/           # Mock P&ID text files
â”‚       â”œâ”€â”€ TeraField_Midland_Hub_Process_Flow.txt
â”‚       â”œâ”€â”€ Shift_Report_2023_10_12.txt
â”‚       â””â”€â”€ Maintenance_Log_V204.txt
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 01_setup.sql         # Infrastructure (DB, WH, Network Rule)
â”‚   â”œâ”€â”€ 02_tables.sql        # DDL + data loading
â”‚   â”œâ”€â”€ 03_cortex_search.sql # Search service
â”‚   â”œâ”€â”€ 04_semantic_view.sql # Semantic view
â”‚   â””â”€â”€ 05_cortex_agent.sql  # Agent deployment
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ autogl_link_prediction.ipynb
â”œâ”€â”€ semantic_views/
â”‚   â””â”€â”€ permian_analytics.yaml
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ integration_assistant.json
â”œâ”€â”€ streamlit/
â”‚   â”œâ”€â”€ snowflake.yml
â”‚   â”œâ”€â”€ environment.yml
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ data_loader.py    # Parallel query utility
â”‚   â””â”€â”€ pages/
â”‚       â”œâ”€â”€ 1_Network_Map.py
â”‚       â””â”€â”€ 2_Simulation_Chat.py
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ generate_synthetic_data.py
â”œâ”€â”€ deploy.sh
â”œâ”€â”€ clean.sh
â””â”€â”€ README.md
```

## Demo Script

### Scenario: "Can we route 5,000 extra barrels through Midland Hub?"

1. **Open Simulation & Chat page**

2. **Ask the AI Assistant:**
   > "What is the pressure rating for separator V-204?"
   
   Response: *"Based on the P&ID, TF-V-204 has a MAWP of 600 PSIG..."*

3. **Check Risk Scores:**
   > "Which assets are flagged as high risk?"
   
   Response: *"TF-V-204 has risk score 0.92..."*

4. **Run Simulation:**
   - Select `SC-PAD-42` as source
   - Set production increase to 5,000 BOPD
   - Click "Run Simulation"
   
   Result: **DENIED** - Projected pressure (800 PSI) exceeds TF-V-204 limit (600 PSI)

5. **Show the Hidden Dependency:**
   - View Network Map
   - Enable "Show Predicted Links"
   - See the dashed purple line connecting SC-SEP-101 to TF-V-204

## Cleanup

```bash
# Remove all Snowflake resources (uses default "demo" connection)
./clean.sh

# Or specify a different connection
./clean.sh -c myconnection

# Clean a specific environment
./clean.sh --prefix DEV
./clean.sh --prefix DEV --yes    # Skip confirmation
```

This removes all Snowflake resources. Local files are preserved.

## Author

Tripp Smith - [linkedin.com/in/smithtripp/](https://linkedin.com/in/smithtripp/)

## License

MIT License - See [LICENSE](LICENSE) for details.
